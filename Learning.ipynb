{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4a484df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-13T02:14:34.758207Z",
     "iopub.status.busy": "2022-10-13T02:14:34.757461Z",
     "iopub.status.idle": "2022-10-13T02:15:41.891409Z",
     "shell.execute_reply": "2022-10-13T02:15:41.890105Z"
    },
    "id": "qO29vGOHS8Q8",
    "outputId": "1c13749c-a655-4904-8c77-36b748d4847a",
    "papermill": {
     "duration": 67.144048,
     "end_time": "2022-10-13T02:15:41.894759",
     "exception": false,
     "start_time": "2022-10-13T02:14:34.750711",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyspark\r\n",
      "  Downloading pyspark-3.3.0.tar.gz (281.3 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.3/281.3 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hCollecting py4j==0.10.9.5\r\n",
      "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.7/199.7 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hBuilding wheels for collected packages: pyspark\r\n",
      "  Building wheel for pyspark (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \bdone\r\n",
      "\u001b[?25h  Created wheel for pyspark: filename=pyspark-3.3.0-py2.py3-none-any.whl size=281764026 sha256=d5fb494dcbc13d888f9091dc14f41943d4229bb25292fee666a546ef0b8ad59e\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/7a/8e/1b/f73a52650d2e5f337708d9f6a1750d451a7349a867f928b885\r\n",
      "Successfully built pyspark\r\n",
      "Installing collected packages: py4j, pyspark\r\n",
      "  Attempting uninstall: py4j\r\n",
      "    Found existing installation: py4j 0.10.9.7\r\n",
      "    Uninstalling py4j-0.10.9.7:\r\n",
      "      Successfully uninstalled py4j-0.10.9.7\r\n",
      "Successfully installed py4j-0.10.9.5 pyspark-3.3.0\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip3 install pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e24e0a",
   "metadata": {
    "id": "lOHym6bSZDM4",
    "papermill": {
     "duration": 0.034571,
     "end_time": "2022-10-13T02:15:41.964288",
     "exception": false,
     "start_time": "2022-10-13T02:15:41.929717",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Spark Configuration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f2c1d2e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-13T02:15:42.038527Z",
     "iopub.status.busy": "2022-10-13T02:15:42.038070Z",
     "iopub.status.idle": "2022-10-13T02:15:48.033491Z",
     "shell.execute_reply": "2022-10-13T02:15:48.032124Z"
    },
    "id": "5hK7Il0EYqcN",
    "papermill": {
     "duration": 6.036823,
     "end_time": "2022-10-13T02:15:48.036474",
     "exception": false,
     "start_time": "2022-10-13T02:15:41.999651",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/13 02:15:45 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkContext,SparkConf\n",
    "conf=SparkConf().setAppName(\"test1\").setMaster(\"local[*]\") # The star mentions how many cores we want to use. * means use maximum possible cores.\n",
    "sc=SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3beddd74",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-13T02:15:48.114944Z",
     "iopub.status.busy": "2022-10-13T02:15:48.113487Z",
     "iopub.status.idle": "2022-10-13T02:15:48.122468Z",
     "shell.execute_reply": "2022-10-13T02:15:48.121085Z"
    },
    "papermill": {
     "duration": 0.050236,
     "end_time": "2022-10-13T02:15:48.125403",
     "exception": false,
     "start_time": "2022-10-13T02:15:48.075167",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print(sc.defaultParallelism) # Check number of cores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ed95df",
   "metadata": {
    "id": "Fr5uri2JbjMX",
    "papermill": {
     "duration": 0.036853,
     "end_time": "2022-10-13T02:15:48.198568",
     "exception": false,
     "start_time": "2022-10-13T02:15:48.161715",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Create RDD's and Basic Concepts**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f2a1393",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-13T02:15:48.273607Z",
     "iopub.status.busy": "2022-10-13T02:15:48.273034Z",
     "iopub.status.idle": "2022-10-13T02:15:48.281038Z",
     "shell.execute_reply": "2022-10-13T02:15:48.279203Z"
    },
    "id": "0wNQN76PW4j7",
    "outputId": "3c048325-ddc2-47b5-87d3-c25e6f82c0db",
    "papermill": {
     "duration": 0.048824,
     "end_time": "2022-10-13T02:15:48.283316",
     "exception": false,
     "start_time": "2022-10-13T02:15:48.234492",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 24, 9, 4, 22, 8, 3, 13, 15, 18]\n"
     ]
    }
   ],
   "source": [
    "# Create random list\n",
    "import random\n",
    "\n",
    "random_list=random.sample(range(0,30),10)\n",
    "print(random_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c62a5ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-13T02:15:48.357047Z",
     "iopub.status.busy": "2022-10-13T02:15:48.355833Z",
     "iopub.status.idle": "2022-10-13T02:15:49.658065Z",
     "shell.execute_reply": "2022-10-13T02:15:49.656397Z"
    },
    "id": "Ie0L2adFgeLk",
    "outputId": "e4bdb52e-1156-4d7f-ca54-80f73ba81abf",
    "papermill": {
     "duration": 1.343839,
     "end_time": "2022-10-13T02:15:49.662442",
     "exception": false,
     "start_time": "2022-10-13T02:15:48.318603",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "[2, 24, 9, 4, 22, 8, 3, 13, 15, 18]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Create RDD\n",
    "rdd1=sc.parallelize(random_list,6)  # We create 4 partitions\n",
    "print(rdd1.getNumPartitions())\n",
    "print(rdd1.collect()) # This will collect data from executors and send it to driver. So, be careful while using actions which send output to driver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9680326b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-13T02:15:49.779838Z",
     "iopub.status.busy": "2022-10-13T02:15:49.779451Z",
     "iopub.status.idle": "2022-10-13T02:15:51.043937Z",
     "shell.execute_reply": "2022-10-13T02:15:51.042628Z"
    },
    "id": "8kUHBD9QgrvT",
    "outputId": "3929c4b5-5927-42e3-f922-19eb91057e59",
    "papermill": {
     "duration": 1.321905,
     "end_time": "2022-10-13T02:15:51.048019",
     "exception": false,
     "start_time": "2022-10-13T02:15:49.726114",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[2], [24, 9], [4, 22], [8], [3, 13], [15, 18]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View rdd in each partition\n",
    "rdd1.glom().collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 88.38962,
   "end_time": "2022-10-13T02:15:53.711986",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-10-13T02:14:25.322366",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
